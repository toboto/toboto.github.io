---
layout:     post
title:      "深度学习入门读书笔记-神经网络原理"
subtitle:   "关于神经网络的基本数学原理"
date:       2019-05-05
author:     "toboto"
tags:
    - 神经网络
    - 深度学习
    - Python
    - Neural Networks
---

近期读了《深度学习入门：基于Python的理论与实现》，了解了关于CNN网络的基本结构，也做了一些实践。将写了一些笔记记录下来。前两章节基础知识，没做记录，从第三章开始。
# 第三章 神经网络
## 神经网络的组成方式
将感知机和激活函数连接即可形成一层神经网络。  
![image](http://www.ituring.com.cn/figures/2018/DeepLearning/022.png)
将神经网络写成：

<script type='text/javascript'>
ele = document.createElement("div");
latex = "a = b + w_1x_1 + w_2x_2";
katex.render(latex, ele , katexEqu);
document.write(ele.outerHTML);
</script>
<script type='text/javascript'>
ele = document.createElement("div");
latex = "y = h(a)";
katex.render(latex, ele , katexEqu);
document.write(ele.outerHTML);
</script>
可以将常量<span id='kinline1'></span>也引入到节点中，<span id='kinline2'></span>和<span id='kinline3'></span>表示对输入参数的权重计算，<span id='kinline4'></span>表示该节点的触发灵敏度。  
<span id='kinline5'></span>为激活函数，通过激活函数可以计算输入信号转换为输出信号，以判定输出为1或0。在神经网络的中间层节点中，激活函数返回的可能是连续的数值，而非直接的判定结果。

<script type='text/javascript'>
ele = document.getElementById('kinline1');
latex = "b";
katex.render(latex, ele , katexInline);
ele = document.getElementById('kinline4');
katex.render(latex, ele , katexInline);

ele = document.getElementById('kinline2');
latex = "w_1";
katex.render(latex, ele , katexInline);
ele = document.getElementById('kinline3');
latex = "w_2";
katex.render(latex, ele , katexInline);
ele = document.getElementById('kinline5');
latex = "h(a)";
katex.render(latex, ele , katexInline);
</script>

## 激活函数
### 阶跃函数
当输入超过0时，输出1；否则，输出0。阶跃函数不是连续函数，是判定函数的理想形式
### sigmoid函数
sigmoid函数可表示为：

<script type='text/javascript'>
ele = document.createElement("div");
latex = "h(x) = \\frac{1}{1+e^{-x}}";
katex.render(latex, ele , katexEqu);
document.write(ele.outerHTML);
</script>

sigmoid函数和阶跃函数形状很类似，但它是连续函数，除了可以用于判定，还可以表达实值信号的强度。在神经网络中，sigmoid函数具有重要的意义。

### ReLU函数
ReLU函数输出在输入大于0时为输入本身，在小雨等于0时输出等于0。
<script type='text/javascript'>
ele = document.createElement("div");
latex = "h(x) = \\begin{cases}\n";
latex += "x &\\text{if } x \\gt 0 \\\\\n";
latex += "0 &\\text{if } x \\leq 0\n";
latex += "\\end{cases}";
katex.render(latex, ele , katexEqu);
document.write(ele.outerHTML);
</script>


### 三种激活函数的比较

![image](http://dev-pic.oss-cn-beijing.aliyuncs.com/python/hx.png)

## 多维数组运算
多维数组运算即为矩阵运算，python中用来表示矩阵乘法的函数为
```
np.dot(A, B)
```
采用矩阵的表达方式，一层神经网络可以表示成：

<script type='text/javascript'>
ele = document.createElement("div");
latex = "\\mathbf{X} \\cdot \\mathbf{W} + \\mathbf{B} = \\mathbf{Y}";
katex.render(latex, ele , katexEqu);
document.write(ele.outerHTML);
</script>
其中
<script type='text/javascript'>
ele = document.createElement("div");
latex = "\\mathbf{X} = [x_1, x_2, \\cdots, x_N]\n\\newline";
latex += "\\mathbf{W} = \\begin{bmatrix}\n";
latex += "\\boldsymbol{w_1}, \\boldsymbol{w_2}, \\cdots \\boldsymbol{w_M}\n";
latex += "\\end{bmatrix}\n\\newline";
latex += "\\mathbf{B} = [b_1, b_2, \\cdots, b_M]\n\\newline";
latex += "\\mathbf{Y} = [y_1, y_2, \\cdots, y_M]\n\\newline";
latex += "\\boldsymbol{w_k} = \\begin{bmatrix} w_{k} \\\\ w_{k2} \\\\ \\vdots \\\\ w_{kN} \\end{bmatrix}\n";
katex.render(latex, ele , katexEqu);
document.write(ele.outerHTML);
</script>

## 多层神经网络的传递
### 中间层表达
每一级可以用如下公式表达的神经网络为一层，神经网络可以包含多层。
<script type='text/javascript'>
ele = document.createElement("div");
latex = "\\mathbf{X} \\cdot \\mathbf{W} + \\mathbf{B} = \\mathbf{Y}"
katex.render(latex, ele , katexEqu);
document.write(ele.outerHTML);
</script>

通常将第k层神经网络的权重符号表达为<span id='kinline7'></span>，其中i表示第k层的神经元（本层输出节点），j表示k-1层的神经元（本层输入节点）。

习惯上用<span id='kinline8'></span>来替换<span id='kinline9'></span>。则第一层神经元可表达为：
<script type='text/javascript'>
ele = document.getElementById('kinline7');
latex = "w^{(k)}_{ij}";
katex.render(latex, ele , katexInline);
ele = document.getElementById('kinline8');
latex = "\\mathbf{A}^{(k)}";
katex.render(latex, ele , katexInline);
ele = document.getElementById('kinline9');
latex = "\\mathbf{Y}";
katex.render(latex, ele , katexInline);
</script>
<script type='text/javascript'>
ele = document.createElement("div");
latex = "\\mathbf{A^{(1)}} = \\mathbf{X} \\cdot \\mathbf{W^{(1)}} + \\mathbf{B^{(1)}}";
katex.render(latex, ele , katexEqu);
document.write(ele.outerHTML);
</script>
获得<span id='kinline10'></span>后，可以通过激活函数进行转换，得到：
<script type='text/javascript'>
ele = document.getElementById('kinline10');
latex = "\\mathbf{A^{(1)}}";
katex.render(latex, ele , katexInline);
ele = document.createElement("div");
latex = "\\mathbf{Z^{(1)}} = h(\\mathbf{A^{(1)}})";
katex.render(latex, ele , katexEqu);
document.write(ele.outerHTML);
</script>
例如：<span id='kinline11'></span>。
<span id='kinline12'></span>可以作为下一层神经网络的输入信号。
以此类推，可得对于第k层神经网络：
<script type='text/javascript'>
ele = document.getElementById('kinline11');
latex = "h(x)=sigmoid(x)";
katex.render(latex, ele , katexInline);
ele = document.getElementById('kinline12');
latex = "\\mathbf{Z^{(1)}}";
katex.render(latex, ele , katexInline);
ele = document.createElement("div");
latex = "\\begin{aligned}\\mathbf{Z^{(k)}} &= h(\\mathbf{A^{(k)}}) \\\\";
latex += "&=h \\left( \\mathbf{Z^{(k-1)}} \\cdot \\mathbf{W^{(k)}} + \\mathbf{B^{(k)}} \\right)";
latex += "\\end{aligned}";
katex.render(latex, ele , katexEqu);
document.write(ele.outerHTML);
</script>

### 输出层表达
最后一层，也就是输出层的激活函数，可能和隐藏层不同。一般地，回归问题可以使用恒等函数，二元分类问题可以使用 sigmoid 函数，多元分类问题可以使用 softmax 函数。通常用<span id='kinline13'></span>来表示输出层激活函数，而不是h()。
<script type='text/javascript'>
ele = document.getElementById('kinline12');
latex = "\\sigma()";
katex.render(latex, ele , katexInline);
</script>
#### 恒等函数
恒等函数可表示为：

```
def identity_function(x):
    return x
```

#### softmax函数
softmax函数可表示为：
<script type='text/javascript'>
ele = document.createElement("div");
latex = "y_k = \\frac{e^{a_k}}{\\displaystyle\\sum_{i=1}^n e^{a_i}}";
katex.render(latex, ele , katexEqu);
document.write(ele.outerHTML);
</script>

softmax函数对一组参数取指数，随后计算每一个非线性变化后的参数结果占总体的比例。
代码上可以做如下实现：
```
def softmax(a):
    exp_a = np.exp(a)
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a

    return y
```

##### softmax函数溢出问题
softmax函数要考虑溢出的问题，因为指数随着输入参数的变大会快速增大，最终可能会超过一个数值存储单元的最大数值。
由于指数函数的特性，我们可以将softmax函数的分子分母同时乘以一个常数，最终这个常数将变为指数上与输入参数求和的常数。如下所示：
<script type='text/javascript'>
ele = document.createElement("div");
latex = "\\begin{aligned}";
latex += "y_k &= \\frac{Ce^{a_k}}{C\\displaystyle\\sum_{i=1}^n e^{a_i}} \\\\";
latex += "&=\\frac{e^{(a_k+C')}}{\\displaystyle\\sum_{i=1}^n e^{(a_i+C')}}";
latex += "\\end{aligned}";
katex.render(latex, ele , katexEqu);
document.write(ele.outerHTML);
</script>
如果取<span id='kinline13'></span>，则可以将softmax函数中的指数值进行等比例缩减，且最大值为1（<span id='kinline14'></span>），避免了溢出的问题。
<script type='text/javascript'>
ele = document.getElementById('kinline13');
latex = "C'= -1 \times max(a_1, a_2, \cdots, a_N)";
katex.render(latex, ele , katexInline);
ele = document.getElementById('kinline14');
latex = "e^0=1";
katex.render(latex, ele , katexInline);
</script>

##### softmax函数的特征
softmax函数任意一项总是介于0~1之间，且对所有输出项求和总是等于1。这个特征使得softmax函数可以被视为“概率”。

## 手写数字识别示例
这一示例主要展示了对于已有网络如何通过测试序列对网络性能做出判断。一般地，会将已知的序列分为训练序列和测试序列。训练序列用于生成网络参数，测试序列用于验证网络的准确性。在Python中成批进行矩阵计算，可以充分利用矩阵据算的特点，提高计算效率。

